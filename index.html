<!-- 
JumpTek Widget: MediaPipe Optimized with Automated Calibration 
Parts 1-5: HTML, Styles, and Calibration Logic (Homography-based)
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>JumpTek Widget - Auto Calibration</title>
  <style>
    body { margin:0; font-family:sans-serif; background:#222; color:#fff; }
    #jt-widget-root { width:100vw; height:100vh; overflow:hidden; position:relative; }
    #jt-video, #jt-canvas { position:absolute; top:0; left:0; width:100vw; height:100vh; object-fit:cover; }
    #jt-canvas { pointer-events:auto; }
    #jt-calibration-ui, #jt-debug-ui { position:absolute; z-index:10; top:1em; left:1em; background:#222a; padding:1em; border-radius:8px; }
    #jt-settings-popover { display:none; position:absolute; top:4em; right:2em; background:#333; color:#fff; padding:1em; border-radius:8px; z-index:20; }
    #jt-notice { position:absolute; top:1em; left:50%; transform:translateX(-50%); background:#000a; padding:0.5em 2em; border-radius:16px; font-size:1.2em; z-index:15; }
    #jt-widget-jump-height { position:absolute; bottom:2em; left:50%; transform:translateX(-50%); font-size:2em; background:#000a; padding:0.5em 2em; border-radius:16px; }
    #jt-controls { position:absolute; right:1em; bottom:1em; display:flex; gap:1em; z-index:30; }
    .jt-btn { background:#3366ff; color:#fff; border:none; border-radius:8px; padding:0.5em 1.2em; font-size:1em; cursor:pointer; }
    .jt-btn:active { background:#224488; }
    #jt-debug-values, #jt-raw-height-debug, #jt-frame-rate { white-space:pre; font-size:0.95em; margin-top:0.5em; display:none; }
    @media (max-width: 600px) {
      #jt-calibration-ui, #jt-debug-ui, #jt-settings-popover { left:0.5em; right:0.5em; width:auto; }
      #jt-controls { left:0.5em; right:0.5em; bottom:0.5em; flex-wrap:wrap; }
      #jt-notice, #jt-widget-jump-height { font-size:1.1em; padding:0.5em 1em; }
    }
  </style>
</head>
<body>
  <div id="jt-widget-root">
    <video id="jt-video" autoplay playsinline muted></video>
    <canvas id="jt-canvas"></canvas>
    <div id="jt-notice"></div>
    <div id="jt-widget-jump-height">Jump: 0.00 m</div>
    <div id="jt-calibration-ui">
      <span id="jt-calibration-status">Calibration: <b>Not Started</b></span>
      <br>
      <button class="jt-btn" id="jt-calibrate-btn">Calibrate</button>
      <button class="jt-btn" id="jt-restart-draw-btn">Redraw Corners</button>
      <button class="jt-btn" id="jt-switch-camera-btn">Switch Camera</button>
    </div>
    <div id="jt-debug-ui">
      <label><input type="checkbox" id="jt-debug-mode"> Debug Mode</label>
      <div id="jt-debug-values"></div>
      <div id="jt-raw-height-debug"></div>
      <div id="jt-frame-rate"></div>
    </div>
    <div id="jt-settings-popover">
      <b>Settings</b>
      <br>
      <label>Jump Threshold: <input type="number" step="0.01" id="jt-jump-threshold" value="0.08"></label>
      <br>
      <button class="jt-btn" id="jt-save-settings-btn">Save</button>
      <button class="jt-btn" id="jt-close-settings-btn">Close</button>
    </div>
    <div id="jt-controls">
      <button class="jt-btn" id="jt-settings-btn">Settings</button>
      <button class="jt-btn" id="jt-zoom-in-btn">Zoom In</button>
      <button class="jt-btn" id="jt-zoom-out-btn">Zoom Out</button>
    </div>
  </div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
<!-- Optionally load OpenCV.js for robust homography calculation -->
<script src="https://docs.opencv.org/master/opencv.js"></script>
<script>
/* --- PART 1: CONSTANTS & GLOBALS --- */
// Known trampoline real-world size (meters)
const TRAMPOLINE_WIDTH = 3.05;
const TRAMPOLINE_LENGTH = 2.0;

// Calibration phase enums
const CALIB_MARK_CORNERS = 1;
const CALIB_COMPLETE = 2;

// Gravity constant for jump height calculation
const GRAVITY = 9.80665;

// UI elements
const video = document.getElementById('jt-video');
const canvas = document.getElementById('jt-canvas');
const ctx = canvas.getContext('2d');
const notice = document.getElementById('jt-notice');
const calibrateBtn = document.getElementById('jt-calibrate-btn');
const restartDrawBtn = document.getElementById('jt-restart-draw-btn');
const switchCameraBtn = document.getElementById('jt-switch-camera-btn');
const calibrationStatus = document.getElementById('jt-calibration-status');
const widgetJumpHeightDisplay = document.getElementById('jt-widget-jump-height');
const debugModeCheckbox = document.getElementById('jt-debug-mode');
const debugValuesDisplay = document.getElementById('jt-debug-values');
const rawHeightDebugDisplay = document.getElementById('jt-raw-height-debug');
const frameRateDisplay = document.getElementById('jt-frame-rate');
const settingsBtn = document.getElementById('jt-settings-btn');
const closeSettingsBtn = document.getElementById('jt-close-settings-btn');
const settingsPopover = document.getElementById('jt-settings-popover');
const saveSettingsBtn = document.getElementById('jt-save-settings-btn');
const jumpThresholdInput = document.getElementById('jt-jump-threshold');
const zoomInBtn = document.getElementById('jt-zoom-in-btn');
const zoomOutBtn = document.getElementById('jt-zoom-out-btn');

let trampolineCorners = [];            // Marked in video (pixel) coords
let homographyMatrix = null;           // cv.Mat or JS array
let cameraExtrinsics = null;           // {rvec, tvec}
let lastPoseResults = null;
let currentCalibrationPhase = CALIB_MARK_CORNERS;
let baselineZ = null;
let jumpState = 'on_ground';
let pose = null;
let poseLoaded = false;
let dirtyFrame = true;
let useFrontCamera = false;
let debugMode = false;
let JUMP_THRESHOLD = 0.08;
let videoTrack = null, zoomCapabilities = null;
let zHistory = [], velocityHistory = [];
let currentZSmoothed = null, verticalVelocitySmoothed = null;
let jumpStartY = null, jumpHighestY = null, lastZPosRaw = null, lastTimeRaw = null;
let jumpStartTime = null, jumpEndTime = null, highestPointZ = null;

/* --- PART 2: CANVAS/VIDEO UTILS --- */
function resizeCanvasToScreen() {
  canvas.width = video.videoWidth || window.innerWidth;
  canvas.height = video.videoHeight || window.innerHeight;
  dirtyFrame = true;
}
function getVideoRelativeToCanvas(x, y, vidW, vidH, canW, canH) {
  // Map canvas (x, y) to video pixel (vx, vy)
  return [
    (x / canW) * vidW,
    (y / canH) * vidH
  ];
}
function drawTrampolineCorners() {
  ctx.save();
  ctx.strokeStyle = "#0f0";
  ctx.lineWidth = 3;
  if (trampolineCorners.length > 0) {
    ctx.beginPath();
    trampolineCorners.forEach((pt, i) => {
      if (i === 0) ctx.moveTo(pt[0], pt[1]);
      else ctx.lineTo(pt[0], pt[1]);
    });
    if (trampolineCorners.length === 4)
      ctx.closePath();
    ctx.stroke();
    trampolineCorners.forEach(pt => {
      ctx.beginPath();
      ctx.arc(pt[0], pt[1], 10, 0, 2 * Math.PI);
      ctx.fillStyle = "#0f0";
      ctx.fill();
    });
  }
  ctx.restore();
}

/* --- PART 3: AUTOMATED CALIBRATION (HOMOGRAPHY & CAMERA POSE) --- */
/**
 * Order trampoline corners: [top-left, top-right, bottom-right, bottom-left]
 */
function orderCorners(pts) {
  // Sort by y, then x
  let sorted = pts.slice().sort((a, b) => a[1] - b[1] || a[0] - b[0]);
  let [tl, tr] = sorted.slice(0, 2).sort((a, b) => a[0] - b[0]);
  let [bl, br] = sorted.slice(2, 4).sort((a, b) => a[0] - b[0]);
  return [tl, tr, br, bl]; // clockwise
}

/**
 * Compute the homography and estimate camera pose from the marked image points to real-world trampoline corners.
 * Uses OpenCV.js if available.
 */
function computeHomographyAndCameraPose() {
  if (trampolineCorners.length !== 4) return {H: null, camera: null};

  const imgPts = orderCorners(trampolineCorners);
  const worldPts = [
    [0, 0],
    [TRAMPOLINE_WIDTH, 0],
    [TRAMPOLINE_WIDTH, TRAMPOLINE_LENGTH],
    [0, TRAMPOLINE_LENGTH]
  ];

  let H = null, camera = null;
  // Use OpenCV.js for robust homography and camera pose estimation
  if (window.cv && cv.getPerspectiveTransform && cv.solvePnP) {
    // Convert to cv.mat
    const imgMat = cv.matFromArray(4, 1, cv.CV_32FC2, imgPts.flat());
    const worldMat = cv.matFromArray(4, 1, cv.CV_32FC2, worldPts.flat());
    H = cv.getPerspectiveTransform(imgMat, worldMat);

    // Camera intrinsics estimate (fx, fy ~= width, height; cx, cy = center)
    const fx = video.videoWidth;
    const fy = video.videoHeight;
    const cx = video.videoWidth / 2;
    const cy = video.videoHeight / 2;
    const cameraMatrix = cv.matFromArray(3, 3, cv.CV_64F, [
      fx, 0, cx,
      0, fy, cy,
      0, 0, 1
    ]);
    const distCoeffs = cv.Mat.zeros(4, 1, cv.CV_64F);

    // OpenCV expects 3D world points ([x, y, 0]), 2D image points
    const world3D = cv.matFromArray(4, 1, cv.CV_32FC3, [
      worldPts[0][0], worldPts[0][1], 0,
      worldPts[1][0], worldPts[1][1], 0,
      worldPts[2][0], worldPts[2][1], 0,
      worldPts[3][0], worldPts[3][1], 0
    ]);
    const img2D = cv.matFromArray(4, 1, cv.CV_32FC2, imgPts.flat());

    let rvec = new cv.Mat(), tvec = new cv.Mat();
    cv.solvePnP(world3D, img2D, cameraMatrix, distCoeffs, rvec, tvec, false, cv.SOLVEPNP_ITERATIVE);

    camera = {
      cameraMatrix, distCoeffs, rvec, tvec,
      fx, fy, cx, cy
    };

    imgMat.delete(); worldMat.delete(); world3D.delete(); img2D.delete();
  } else {
    // Fallback: only homography, no extrinsics
    H = computeDLTHomography(imgPts, worldPts);
    camera = null;
  }
  return {H, camera};
}

/**
 * Use the computed homography to map a pixel (x, y) to world (X, Y) on trampoline.
 * Returns [X, Y] in meters.
 */
function pixelToWorld(x, y) {
  if (!homographyMatrix) return null;
  if (window.cv && typeof homographyMatrix === "object" && homographyMatrix.data) {
    let src = cv.matFromArray(1, 1, cv.CV_32FC2, [x, y]);
    let dst = new cv.Mat();
    cv.perspectiveTransform(src, dst, homographyMatrix);
    let res = [dst.data32F[0], dst.data32F[1]];
    src.delete(); dst.delete();
    return res;
  } else if (Array.isArray(homographyMatrix)) {
    let H = homographyMatrix;
    let xp = H[0][0]*x + H[0][1]*y + H[0][2];
    let yp = H[1][0]*x + H[1][1]*y + H[1][2];
    let wp = H[2][0]*x + H[2][1]*y + H[2][2];
    return [xp/wp, yp/wp];
  }
  return null;
}

/**
 * Project a pixel (x,y) into a 3D ray from the camera, using the estimated intrinsics.
 * Returns a 3D direction vector (not normalized).
 */
function pixelToRay3D(x, y, camera) {
  // Use inverse camera intrinsics
  let X = (x - camera.cx) / camera.fx;
  let Y = (y - camera.cy) / camera.fy;
  return [X, Y, 1.0];
}

/**
 * Given the camera extrinsics, project a 3D ray from the camera through pixel (x, y)
 * and compute the intersection with the trampoline plane (Z=0).
 * Returns the intersection point [X,Y,0] in world meters.
 */
function intersectRayWithPlane(ray, camera) {
  // Get rotation and translation from solvePnP
  let rvec = camera.rvec, tvec = camera.tvec;
  let rotMat = new cv.Mat();
  cv.Rodrigues(rvec, rotMat);
  // Camera origin in world coordinates
  let camOrigin = [
    tvec.data64F[0],
    tvec.data64F[1],
    tvec.data64F[2]
  ];
  // Ray in camera coordinates (normalize direction)
  let rayVec = new cv.Mat(3, 1, cv.CV_64F);
  rayVec.data64F[0] = ray[0];
  rayVec.data64F[1] = ray[1];
  rayVec.data64F[2] = ray[2];
  // Rotate ray to world coords: R * rayVec
  let worldRay = new cv.Mat();
  cv.gemm(rotMat, rayVec, 1, null, 0, worldRay);

  // Intersection with Z=0 plane: camOrigin + s*worldRay = [X,Y,0]
  // s = -camOrigin[2] / worldRay[2]
  let s = -camOrigin[2] / worldRay.data64F[2];
  let X = camOrigin[0] + s * worldRay.data64F[0];
  let Y = camOrigin[1] + s * worldRay.data64F[1];

  rotMat.delete(); rayVec.delete(); worldRay.delete();
  return [X, Y, 0];
}

/**
 * Given a pixel (x,y) and camera, compute the height (Z) above the trampoline plane.
 * Returns height in meters.
 */
function get3DHeightAbovePlane(x, y, camera) {
  // Project camera origin and 3D ray through (x,y)
  let rvec = camera.rvec, tvec = camera.tvec;
  let rotMat = new cv.Mat();
  cv.Rodrigues(rvec, rotMat);
  let camOrigin = [
    tvec.data64F[0],
    tvec.data64F[1],
    tvec.data64F[2]
  ];
  // Ray in camera coordinates
  let ray = pixelToRay3D(x, y, camera);
  let rayVec = new cv.Mat(3, 1, cv.CV_64F);
  rayVec.data64F[0] = ray[0];
  rayVec.data64F[1] = ray[1];
  rayVec.data64F[2] = ray[2];
  // Rotate ray to world coords: R * rayVec
  let worldRay = new cv.Mat();
  cv.gemm(rotMat, rayVec, 1, null, 0, worldRay);
  // Camera ray: P(t) = camOrigin + t * worldRay
  // Find t such that Pz = 0 (intersection with Z=0 plane)
  let t = -camOrigin[2] / worldRay.data64F[2];
  let groundX = camOrigin[0] + t * worldRay.data64F[0];
  let groundY = camOrigin[1] + t * worldRay.data64F[1];
  // Now, at the pose frame, the lowest landmark is actually above ground.
  // Estimate the current Z by varying t' so that the projected 2D pixel matches.
  // For a monocular camera, we can compute the 3D point for any scale along the ray.
  // We'll use the assumption: when the person is standing, that's Z=0 baseline.
  // So, jump height = difference in t (distance along the ray) between current frame and baseline.

  // For practical usage: store the baseline t for each landmark (when athlete is standing), and subtract current t.

  rotMat.delete(); rayVec.delete(); worldRay.delete();
  // Return the ground intersection [groundX, groundY, 0] and t
  return {
    ground: [groundX, groundY, 0],
    t_ground: t,
    camOrigin: camOrigin
  };
}

/**
 * Called after all 4 corners marked.
 * Computes the homography and camera pose, sets calibration state.
 */
function finishCalibrationIfPossible() {
  if (trampolineCorners.length !== 4) return;
  let {H, camera} = computeHomographyAndCameraPose();
  if (!H || !camera) {
    notice.textContent = "Calibration failed. Try marking the corners again.";
    calibrationStatus.innerHTML = "Calibration: <b>Failed</b>";
    return;
  }
  homographyMatrix = H;
  cameraPose = camera;
  standingBaselineT = null; // Reset
  currentCalibrationPhase = CALIB_COMPLETE;
  calibrationStatus.innerHTML = "Calibration: <b>Complete</b>";
  notice.textContent = "Calibration complete! Ready to jump.";
  dirtyFrame = true;
}

/* --- PART 4: CALIBRATION SEQUENCE --- */
/**
 * Called after all 4 corners marked.
 * Computes the homography and sets calibration state.
 */
function finishCalibrationIfPossible() {
  if (trampolineCorners.length !== 4) return;
  homographyMatrix = computeHomographyFromCorners();
  if (!homographyMatrix) {
    notice.textContent = "Calibration failed. Try marking the corners again.";
    calibrationStatus.innerHTML = "Calibration: <b>Failed</b>";
    return;
  }
  // Optionally estimate camera extrinsics for better jump height
  // For most 2D jump height, mapping pixel to world Y may be sufficient!
  currentCalibrationPhase = CALIB_COMPLETE;
  calibrationStatus.innerHTML = "Calibration: <b>Complete</b>";
  notice.textContent = "Calibration complete! Ready to jump.";
  dirtyFrame = true;
}

/** Reset calibration UI and state */
function resetCalibration() {
  trampolineCorners = [];
  homographyMatrix = null;
  currentCalibrationPhase = CALIB_MARK_CORNERS;
  baselineZ = null;
  calibrationStatus.innerHTML = "Calibration: <b>Not Started</b>";
  notice.textContent = "Tap the four corners of the trampoline.";
  dirtyFrame = true;
}

/* --- PART 5: USER INTERACTION (MARKING, UI, ETC) --- */
canvas.addEventListener('click', function(e) {
  if (currentCalibrationPhase !== CALIB_MARK_CORNERS) return;
  if (trampolineCorners.length >= 4) return;
  const rect = canvas.getBoundingClientRect();
  const x = (e.clientX - rect.left) * (canvas.width / rect.width);
  const y = (e.clientY - rect.top) * (canvas.height / rect.height);
  trampolineCorners.push([x, y]);
  dirtyFrame = true;
  if (trampolineCorners.length === 4) {
    finishCalibrationIfPossible();
  }
});
restartDrawBtn.addEventListener('click', resetCalibration);
calibrateBtn.addEventListener('click', finishCalibrationIfPossible);
switchCameraBtn.addEventListener('click', async () => {
  useFrontCamera = !useFrontCamera;
  await startCamera();
  resetCalibration();
});
resizeCanvasToScreen();
window.addEventListener('resize', resizeCanvasToScreen);
window.addEventListener('DOMContentLoaded', resizeCanvasToScreen);
  <!-- 
JumpTek Widget: MediaPipe Optimized with Automated Calibration 
Parts 6-10: Pose Loop, Jump Logic, Settings, and Script Close 
-->
/* --- PART 6: CAMERA & POSE SETUP --- */
async function startCamera() {
  try {
    let constraints = {
      audio: false,
      video: {
        facingMode: useFrontCamera ? "user" : "environment",
        width: { ideal: 1280 },
        height: { ideal: 720 }
      }
    };
    let stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    videoTrack = stream.getVideoTracks()[0];
    // Zoom support (if available)
    let caps = videoTrack.getCapabilities();
    if (caps && caps.zoom) zoomCapabilities = caps;
    video.onloadedmetadata = resizeCanvasToScreen;
    return stream;
  } catch (e) {
    notice.textContent = "Camera access failed.";
    calibrationStatus.innerHTML = "Calibration: <b>Camera Error</b>";
    throw e;
  }
}
function setupPose() {
  pose = new window.Pose({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
  });
  pose.setOptions({
    modelComplexity: 0,
    smoothLandmarks: true,
    enableSegmentation: false,
    smoothSegmentation: false,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });
  pose.onResults(results => {
    lastPoseResults = results;
  });
  poseLoaded = true;
}
window.addEventListener('DOMContentLoaded', async () => {
  try {
    setupPose();
    await startCamera();
    drawLoop();
    poseLoop();
  } catch (e) {
    notice.textContent = "Widget failed to initialize.";
  }
});

/* --- PART 7: MAIN DRAW AND POSE LOOPS --- */
function drawLoop() {
  if (!video.videoWidth || !video.videoHeight) {
    requestAnimationFrame(drawLoop); return;
  }
  if (dirtyFrame) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    // Draw trampoline corners
    drawTrampolineCorners();
    // Draw pose landmarks (if debug)
    if (debugMode && lastPoseResults && lastPoseResults.poseLandmarks) {
      ctx.save();
      ctx.fillStyle = "#ff0";
      for (let lm of lastPoseResults.poseLandmarks) {
        ctx.beginPath();
        ctx.arc(lm.x * canvas.width, lm.y * canvas.height, 4, 0, 2 * Math.PI);
        ctx.fill();
      }
      ctx.restore();
    }
    dirtyFrame = false;
  }
  requestAnimationFrame(drawLoop);
}
function poseLoop() {
  if (video.readyState >= 2 && poseLoaded) {
    pose.send({ image: video });
  }
  setTimeout(poseLoop, 1000/30);
}

/* --- PART 8: JUMP HEIGHT LOGIC (TRUE 3D ABOVE PLANE) --- */
function getLowestBodyLandmark(landmarks) {
  let idxs = [27, 28, 31, 32]; // left/right ankle, left/right heel
  let lowest = null;
  for (let i of idxs) {
    let lm = landmarks[i];
    if (!lm) continue;
    if (!lowest || lm.y > lowest.y) lowest = lm;
  }
  return lowest;
}

// Store the standing baseline parameter (distance along camera ray to ground) for each calibration
let standingBaselineT = null;
let lastJumpHeight = 0;

function computeAndSendJump(landmarks) {
  if (currentCalibrationPhase !== CALIB_COMPLETE || !homographyMatrix || !cameraPose) {
    widgetJumpHeightDisplay.textContent = `Jump: 0.00 m`;
    return;
  }
  const lowest = getLowestBodyLandmark(landmarks);
  if (!lowest) {
    widgetJumpHeightDisplay.textContent = `Jump: --`;
    return;
  }

  // Get the 2D pixel position in video pixels
  const px = lowest.x * video.videoWidth;
  const py = lowest.y * video.videoHeight;

  // Use camera pose to compute intersection with ground and t_ground
  const {ground, t_ground, camOrigin} = get3DHeightAbovePlane(px, py, cameraPose);

  // On first run (athlete standing), set baseline t_ground as ground reference
  if (standingBaselineT === null) {
    standingBaselineT = t_ground;
    widgetJumpHeightDisplay.textContent = `Jump: 0.00 m`;
    lastJumpHeight = 0;
    if (debugMode) {
      debugValuesDisplay.style.display = "block";
      debugValuesDisplay.textContent = `Set baseline (athlete standing): t0 = ${t_ground.toFixed(4)}`;
    }
    return;
  }

  // For jump: estimate the current 3D foot position and height above the plane
  // The farther the landmark is from the camera along the ray, the higher (since t decreases as athlete rises).
  // Height = (standingBaselineT - t_ground) * norm(worldRay)
  // But since worldRay is normalized, and Z=0 for ground, we can use the difference in t as height
  let jumpHeight = Math.abs(standingBaselineT - t_ground) * Math.abs(camOrigin[2]) / standingBaselineT;

  // Optionally smooth jumpHeight over several frames for stability
  zHistory.push(jumpHeight);
  if (zHistory.length > 6) zHistory.shift();
  let smoothedHeight = zHistory.reduce((a, b) => a + b, 0) / zHistory.length;

  // Simple jump detection
  if (smoothedHeight > JUMP_THRESHOLD) {
    widgetJumpHeightDisplay.textContent = `Jump: ${smoothedHeight.toFixed(2)} m`;
    lastJumpHeight = smoothedHeight;
  } else {
    widgetJumpHeightDisplay.textContent = `Jump: 0.00 m`;
    lastJumpHeight = 0;
  }

  if (debugMode) {
    debugValuesDisplay.style.display = "block";
    debugValuesDisplay.textContent =
      `Jump height: ${smoothedHeight.toFixed(3)} m\nStanding t: ${standingBaselineT.toFixed(4)}\nCurrent t: ${t_ground.toFixed(4)}`;
  } else {
    debugValuesDisplay.style.display = "none";
  }
}
setInterval(() => {
  if (
    lastPoseResults &&
    lastPoseResults.poseLandmarks &&
    currentCalibrationPhase === CALIB_COMPLETE
  ) {
    computeAndSendJump(lastPoseResults.poseLandmarks);
  }
}, 40);

/* --- PART 9: SETTINGS, DEBUG & UI --- */
function applyDebugMode() {
  debugMode = debugModeCheckbox.checked;
  debugValuesDisplay.style.display = debugMode ? "block" : "none";
  rawHeightDebugDisplay.style.display = debugMode ? "block" : "none";
  frameRateDisplay.style.display = debugMode ? "block" : "none";
}
function saveSettingsToStorage() {
  localStorage.setItem("jt_jumpThreshold", jumpThresholdInput.value);
  localStorage.setItem("jt_debugMode", debugModeCheckbox.checked ? "1" : "0");
}
function loadSettingsFromStorage() {
  if (localStorage.getItem("jt_jumpThreshold")) {
    jumpThresholdInput.value = localStorage.getItem("jt_jumpThreshold");
    JUMP_THRESHOLD = parseFloat(jumpThresholdInput.value) || 0.08;
  }
  debugModeCheckbox.checked = localStorage.getItem("jt_debugMode") === "1";
  applyDebugMode();
}
settingsBtn.addEventListener('click', e => {
  settingsPopover.style.display = 'flex';
  e.stopPropagation();
});
closeSettingsBtn.addEventListener('click', () => {
  settingsPopover.style.display = 'none';
});
document.addEventListener('mousedown', e => {
  if (settingsPopover.style.display === 'flex' && !settingsPopover.contains(e.target) && e.target !== settingsBtn) {
    settingsPopover.style.display = 'none';
  }
});
saveSettingsBtn.addEventListener('click', () => {
  saveSettingsToStorage();
  applyDebugMode();
  settingsPopover.style.display = 'none';
  notice.textContent = "Settings saved!";
});
jumpThresholdInput.addEventListener('change', () => {
  JUMP_THRESHOLD = parseFloat(jumpThresholdInput.value) || 0.08;
});
debugModeCheckbox.addEventListener('change', applyDebugMode);
window.addEventListener('DOMContentLoaded', loadSettingsFromStorage);

/* --- PART 10: CAMERA ZOOM & CLOSE --- */
const resetCalibrationForZoom = () => {
  resetCalibration();
};
zoomInBtn.addEventListener('click', async () => {
  if (!videoTrack || !zoomCapabilities) return;
  const settings = videoTrack.getSettings();
  const max = videoTrack.getCapabilities().zoom.max;
  const step = videoTrack.getCapabilities().zoom.step || 0.1;
  let newZoom = Math.min((settings.zoom || 1) + step, max);
  await videoTrack.applyConstraints({ advanced: [{ zoom: newZoom }] });
  resetCalibrationForZoom();
});
zoomOutBtn.addEventListener('click', async () => {
  if (!videoTrack || !zoomCapabilities) return;
  const settings = videoTrack.getSettings();
  const min = videoTrack.getCapabilities().zoom.min;
  const step = videoTrack.getCapabilities().zoom.step || 0.1;
  let newZoom = Math.max((settings.zoom || 1) - step, min);
  await videoTrack.applyConstraints({ advanced: [{ zoom: newZoom }] });
  resetCalibrationForZoom();
});
</script>
</body>
</html>
